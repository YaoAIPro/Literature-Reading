# 个人论文精读

## 大模型系列

|     日期     |                           论文标题                           |
| :----------: | :----------------------------------------------------------: |
| 2024年9月7日 | [**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://mp.weixin.qq.com/s?__biz=MzkxNzc0MzQyMA==&mid=2247483775&idx=1&sn=3e1a248c208bcc1ddc8586be297cbc7a&chksm=c1bab32cf6cd3a3a0d3de054514c06b15501a405b1b09e76d28ddc91715d50fd384e92202363&token=646122533&lang=zh_CN#rd) |





# 代码复现系列

|     日期      |            模型            |                             笔记                             |                     代码                      |
| :-----------: | :------------------------: | :----------------------------------------------------------: | :-------------------------------------------: |
| 2024年9月20日 | BERT-Tensorflow-GPU-2.10.0 | https://mp.weixin.qq.com/s/0yhLIBFosBHe7QYvcoNI7g?token=224962903&lang=zh_CN | https://github.com/YaoAIPro/bert-reproduction |

喜欢我的内容可以扫描以下二维码关注公众号，以更快获取我的最新消息

![fb30ee5e83ffd1918bd07a8aeb590f9](./image/fb30ee5e83ffd1918bd07a8aeb590f9.jpg)