# 个人论文精读

## 大模型系列

|     日期     |                           论文标题                           |
| :----------: | :----------------------------------------------------------: |
| 2024年9月7日 | [**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://mp.weixin.qq.com/s?__biz=MzkxNzc0MzQyMA==&mid=2247483775&idx=1&sn=3e1a248c208bcc1ddc8586be297cbc7a&chksm=c1bab32cf6cd3a3a0d3de054514c06b15501a405b1b09e76d28ddc91715d50fd384e92202363&token=646122533&lang=zh_CN#rd) |



喜欢我的内容可以扫描以下二维码关注公众号，以更快获取我的最新消息


![fb30ee5e83ffd1918bd07a8aeb590f9](https://github.com/user-attachments/assets/aff9efa5-48f4-4bcf-adeb-99b03bed2044)
